[
  {
    "objectID": "certifications.html",
    "href": "certifications.html",
    "title": "Certifications",
    "section": "",
    "text": "Over the past few years, Iâ€™ve actively engaged with a wide range of additional courses to build practical, industry-relevant skills in data analytics, AI, visualisation, and business software. These certifications represent more than just technical knowledge, they reflect my ongoing commitment to continuous learning and applying data-driven insights in real-world scenarios. From early foundations in Excel and Tableau to more advanced concepts in Python, SQL, and AI, each course has contributed to deepening my analytical thinking and problem-solving approach. Collectively, these certifications have given me a strong, well-rounded skill set that Iâ€™ve applied across academic projects, business cases, and technical implementations.\nHere are some selected certifications that represent a broad mix of my technical and analytical development:"
  },
  {
    "objectID": "certifications.html#full-kubicle-certificate-list",
    "href": "certifications.html#full-kubicle-certificate-list",
    "title": "Certifications",
    "section": "Full Kubicle Certificate List",
    "text": "Full Kubicle Certificate List\nBelow is the complete list of my Kubicle certificates:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "David Byrne",
    "section": "",
    "text": "Welcome to my ePortfolio! ðŸ‘‹\nIâ€™m a final-year Business Studies student in DCU specialising in data analytics. Here youâ€™ll find a curated showcase of my projects and work over the last 4 years. This space highlights my skills, interests, and the journey Iâ€™ve taken. Feel free to explore, connect with me on LinkedIn, or reach out to me!\nâ–º Learn more about me"
  },
  {
    "objectID": "about_experience/dcu.html",
    "href": "about_experience/dcu.html",
    "title": "David Byrne",
    "section": "",
    "text": "My time at DCU has been defined by growth, both intellectually and personally. From the moment I arrived as a first-year Business Studies student, I immersed myself in the coursework, celebrating each high-scoring exam, and learning how to approach problems with curiosity and precision. While moving away from home to live up in college was difficult, it has really defined who I am as a person. It taught me adaptability, resilience, and gave me the confidence to embrace new challenges. I picked this course as I wasnâ€™t sure what I wanted to do in life, hence, I left my options open by picking a broad course. I learnt a wide skill set across analytics, finance, marketing, and management, where I then realised that my true interest lies in data analytics and finance. Throughout my degree, I have consistently achieved first-class honours results in each year of my studies, ranking 2nd in a course of over 200 students in the process!\nIn my final year, I decided to serve as a Peer Mentor, helping to guide new students through deadlines, study techniques, and navigation around campus. This has been extremely rewarding, and seeing the studentsâ€™ confidence grow throughout the year has been a real bonus.\nLooking back, itâ€™s the moments of uncertainty, late-night study sessions, navigating group projects, and balancing academics with a new independence that taught me the most. Whether troubleshooting a stubborn dataset, pitching a business idea to investors, or simply finding my way around Dublin, I learned to trust my instincts and seek support when I needed it."
  },
  {
    "objectID": "about_experience/dcu.html#my-dcu-experience",
    "href": "about_experience/dcu.html#my-dcu-experience",
    "title": "David Byrne",
    "section": "",
    "text": "My time at DCU has been defined by growth, both intellectually and personally. From the moment I arrived as a first-year Business Studies student, I immersed myself in the coursework, celebrating each high-scoring exam, and learning how to approach problems with curiosity and precision. While moving away from home to live up in college was difficult, it has really defined who I am as a person. It taught me adaptability, resilience, and gave me the confidence to embrace new challenges. I picked this course as I wasnâ€™t sure what I wanted to do in life, hence, I left my options open by picking a broad course. I learnt a wide skill set across analytics, finance, marketing, and management, where I then realised that my true interest lies in data analytics and finance. Throughout my degree, I have consistently achieved first-class honours results in each year of my studies, ranking 2nd in a course of over 200 students in the process!\nIn my final year, I decided to serve as a Peer Mentor, helping to guide new students through deadlines, study techniques, and navigation around campus. This has been extremely rewarding, and seeing the studentsâ€™ confidence grow throughout the year has been a real bonus.\nLooking back, itâ€™s the moments of uncertainty, late-night study sessions, navigating group projects, and balancing academics with a new independence that taught me the most. Whether troubleshooting a stubborn dataset, pitching a business idea to investors, or simply finding my way around Dublin, I learned to trust my instincts and seek support when I needed it."
  },
  {
    "objectID": "about_experience/dcu.html#representing-the-university-in-the-us",
    "href": "about_experience/dcu.html#representing-the-university-in-the-us",
    "title": "David Byrne",
    "section": "Representing the University in the US",
    "text": "Representing the University in the US\n\nIn January 2025, I was lucky enough to be one of four students selected from the DCU Business School to represent the university at the Schlesinger Global Family Enterprise Case Competition in Burlington, Vermont, USA. This experience was definitely the biggest highlight of my time at university. We spent a week dissecting our pre-arrival case, then faced three days of closed cases, each limited to just four hours of offline analysis. In that tight window, we identified the problems, developed 3 recommendations as well as alternative recommendations, mapped out implementation timelines, and created presentation slides. We then presented for 20 minutes to a talented panel of judges, from private equity managers to retired Amazon executives, where they then quizzed us for a ten-minute Q&A session. There was intense time pressure as we had barely any time to rehearse our pitches before presenting, but our preparation and trust in one another paid off as we topped our division every single day, earning a perfect score of 16/16 points. Competing against universities from the US, Canada, Mexico, and Germany, I saw my presentation skills sharpen, my ability to remain composed under extreme time constraints deepen, and my confidence in group collaboration soar.\nOutside of competition hours, exploring Burlingtonâ€™s snowy streets reminded me that growth often happens outside our comfort zones, and that the friendships and professional lessons gained are among my most treasured takeaways from DCU."
  },
  {
    "objectID": "projects/SQL/SQL_exam.html",
    "href": "projects/SQL/SQL_exam.html",
    "title": "SQL Exam Code",
    "section": "",
    "text": "-- Remove any old tables\nDROP TABLE IF EXISTS Orders;\nDROP TABLE IF EXISTS Products;\nDROP TABLE IF EXISTS Customers;\n\n-- Create a new database and switch into it\nCREATE DATABASE TechCie;\nUSE TechCie;"
  },
  {
    "objectID": "projects/SQL/SQL_exam.html#setup-database-creation",
    "href": "projects/SQL/SQL_exam.html#setup-database-creation",
    "title": "SQL Exam Code",
    "section": "",
    "text": "-- Remove any old tables\nDROP TABLE IF EXISTS Orders;\nDROP TABLE IF EXISTS Products;\nDROP TABLE IF EXISTS Customers;\n\n-- Create a new database and switch into it\nCREATE DATABASE TechCie;\nUSE TechCie;"
  },
  {
    "objectID": "projects/SQL/SQL_exam.html#table-definitions",
    "href": "projects/SQL/SQL_exam.html#table-definitions",
    "title": "SQL Exam Code",
    "section": "2. Table Definitions",
    "text": "2. Table Definitions\n-- Customers table\nCREATE TABLE Customers (\n  Customer_ID   INT PRIMARY KEY,\n  Customer_Name VARCHAR(20),\n  Email         VARCHAR(30)\n);\n\n-- Products table\nCREATE TABLE Products (\n  Product_ID   INT PRIMARY KEY,\n  Product_Name VARCHAR(20),\n  Price        FLOAT\n);\n\n-- Orders table, with foreign keys\nCREATE TABLE Orders (\n  Order_ID     INT PRIMARY KEY,\n  Customer_ID  INT,\n  Product_ID   INT,\n  Quantity     INT,\n  Order_Date   DATE,\n  FOREIGN KEY (Customer_ID) REFERENCES Customers(Customer_ID),\n  FOREIGN KEY (Product_ID)  REFERENCES Products(Product_ID)\n);"
  },
  {
    "objectID": "projects/SQL/SQL_exam.html#insert-sample-data",
    "href": "projects/SQL/SQL_exam.html#insert-sample-data",
    "title": "SQL Exam Code",
    "section": "3. Insert Sample Data",
    "text": "3. Insert Sample Data\n-- Populate Customers\nINSERT INTO Customers (Customer_ID, Customer_Name, Email)\nVALUES\n  (1, 'Alice Smith', 'alice@dcu.com'),\n  (2, 'Bob Johnson', 'bob@dcu.com'),\n  (3, 'Carol Davis', 'carol@ucd.com'),\n  (4, 'David Brown', 'david@tcd.com');\n\n-- Populate Products\nINSERT INTO Products (Product_ID, Product_Name, Price)\nVALUES\n  (101, 'Laptop',    1200),\n  (102, 'Smartphone', 800.5),\n  (103, 'Tablet',     400),\n  (104, 'Monitor',    250),\n  (105, 'Keyboard',    50.5);\n\n-- Populate Orders\nINSERT INTO Orders (Order_ID, Customer_ID, Product_ID, Quantity, Order_Date)\nVALUES\n  (1, 1, 101, 1, '2024-01-15'),\n  (2, 1, 105, 2, '2024-01-16'),\n  (3, 2, 102, 1, '2024-01-15'),\n  (4, 3, 103, 1, '2024-03-05'),\n  (5, 4, 104, 1, '2024-04-15'),\n  (6, 3, 105, 3, '2024-03-15');"
  },
  {
    "objectID": "projects/SQL/SQL_exam.html#explore-the-data",
    "href": "projects/SQL/SQL_exam.html#explore-the-data",
    "title": "SQL Exam Code",
    "section": "4. Explore the Data",
    "text": "4. Explore the Data\n\n4.2 Retrieve product names\nSELECT Product_Name\nFROM Products;\n\n\n4.3 Add new customer\nINSERT INTO Customers (Customer_ID, Customer_Name, Email)\nVALUES (5, 'Ewan Curren', 'ewan@dcu.com');\n\n\n4.4 Update customer email\nUPDATE Customers\nSET Email = 'david@dcu.com'\nWHERE Customer_ID = 4;\n\n\n4.5 Average quantity ordered\nSELECT AVG(Quantity) AS avg_quantity\nFROM Orders;\n\n\n4.6 Products costing more than 300\nSELECT Product_Name\nFROM Products\nWHERE Price &gt; 300;\n\n\n4.7 Customers who ordered on 2024â€‘01â€‘15\nSELECT c.Customer_Name\nFROM Customers AS c\nJOIN Orders    AS o\n  ON c.Customer_ID = o.Customer_ID\nWHERE o.Order_Date = '2024-01-15';\n\n\n4.8 Total quantity per customer after 2024â€‘01â€‘31\nSELECT c.Customer_Name,\n       SUM(o.Quantity) AS Total_Quantity\nFROM Orders    AS o\nJOIN Customers AS c\n  ON o.Customer_ID = c.Customer_ID\nWHERE o.Order_Date &gt; '2024-01-31'\nGROUP BY c.Customer_Name;\n\n\n4.9 Total quantity per customer (include those with no orders)\nSELECT c.Customer_Name,\n       COALESCE(SUM(o.Quantity), 0) AS Total_Quantity\nFROM Customers AS c\nLEFT JOIN Orders AS o\n  ON c.Customer_ID = o.Customer_ID\nGROUP BY c.Customer_Name\nORDER BY Total_Quantity DESC;\n\n\n4.10 Remove Bob Johnson entirely\nDELETE FROM Orders\nWHERE Customer_ID = 2;\n\nDELETE FROM Customers\nWHERE Customer_ID = 2;"
  },
  {
    "objectID": "projects/ned.html",
    "href": "projects/ned.html",
    "title": "New Enterprise Development",
    "section": "",
    "text": "In this module, we were challenged to create a completely novel product, one that hadnâ€™t been brought to market before. Our product, Revive Grounds, is a sustainable skin scrub made using repurposed coffee grounds, and this module gave us the perfect framework to bring it to life. It has been one of the most engaging and practical experiences of my degree so far, offering a strong balance between theory and real-world application. From identifying a clear market opportunity to building investor-ready financials, the process challenged us to think creatively while remaining commercially focused. The Dragonsâ€™ Den pitch was a standout moment, helping us refine our communication and present with confidence to experienced professionals. I also gained a better appreciation for teamwork as we worked closely to develop our brand from the ground up. Overall, the module gave me a much deeper understanding of entrepreneurship and sustainability in business, and helped boost both my practical skills and personal confidence along the way."
  },
  {
    "objectID": "projects/ned.html#my-experience",
    "href": "projects/ned.html#my-experience",
    "title": "New Enterprise Development",
    "section": "",
    "text": "In this module, we were challenged to create a completely novel product, one that hadnâ€™t been brought to market before. Our product, Revive Grounds, is a sustainable skin scrub made using repurposed coffee grounds, and this module gave us the perfect framework to bring it to life. It has been one of the most engaging and practical experiences of my degree so far, offering a strong balance between theory and real-world application. From identifying a clear market opportunity to building investor-ready financials, the process challenged us to think creatively while remaining commercially focused. The Dragonsâ€™ Den pitch was a standout moment, helping us refine our communication and present with confidence to experienced professionals. I also gained a better appreciation for teamwork as we worked closely to develop our brand from the ground up. Overall, the module gave me a much deeper understanding of entrepreneurship and sustainability in business, and helped boost both my practical skills and personal confidence along the way."
  },
  {
    "objectID": "projects/ned.html#marketing-video",
    "href": "projects/ned.html#marketing-video",
    "title": "New Enterprise Development",
    "section": "Marketing Video",
    "text": "Marketing Video\n\n\n\n\n\nWe had to develop a marketing video for our product. This took significant preparation as we had to get professional camera equipment as well as organise with a coffee shop, The Lab, based in Raheny, for us to shoot there. Tackling this assignment was a completely new experience as I had never held a camera or opened editing software before. From storyboarding our concept and setting up shots to learning cut-points, transitions, and sound mixing in editing software, I picked up a unique blend of technical and creative skills. Through late-night editing sessions and feedback loops with teammates, we refined our narrative until it shone, ultimately earning a solid 70%. Beyond the grade, this project gave me newfound confidence in multimedia production and creativity that Iâ€™ll carry into the future."
  },
  {
    "objectID": "projects/ned.html#revive-grounds-business-plan",
    "href": "projects/ned.html#revive-grounds-business-plan",
    "title": "New Enterprise Development",
    "section": "Revive Grounds Business Plan",
    "text": "Revive Grounds Business Plan"
  },
  {
    "objectID": "projects/PowerBI/powerbi.html",
    "href": "projects/PowerBI/powerbi.html",
    "title": "Power BI Dashboards",
    "section": "",
    "text": "Power BI Dashboards"
  },
  {
    "objectID": "projects/business_strat.html",
    "href": "projects/business_strat.html",
    "title": "Business Strategy",
    "section": "",
    "text": "Kerrygold Strategic Evaluation\nFor this year long module, we partook in a group project which accounted for 50% of our final grade. We had to pick a client company in which we would do a strategic evaluation of and propose 3 recommendations. Ornua, with a focus on their consumer brand Kerrygold is who we selected. As we dove into the strategic analyses, from PESTLE and Porterâ€™s Five Forces to VRIO and value-chain mapping, I saw firsthand how each of our team memberâ€™s expertise added depth to the report, which ultimately earned us a grade of 80%. The report can be seen below. Additionally, we had to pitch our analysis, where myself and two others presented, acting as management consultants and we managed to score 78%! These great results set us up really nicely for the individual case analysis which accounted for the other 50% of our final grade.\n\n\n\n\nIndividual Case Study\nFor the individual Hitachi case study, we were tasked with analysing the companyâ€™s strategic challenges and offering a tailored recommendation to address one of them. This involved a deep dive into Hitachiâ€™s complex business portfolio and the macroeconomic forces affecting its direction, where I recommended a strategy to better balance long-term innovation with short-term shareholder pressure. In the second part of the assignment, we critically evaluated Hitachiâ€™s organisational culture and its role in the firmâ€™s pursuit of global expansion, applying frameworks like Scheinâ€™s cultural model and the CAGE distance framework. This section pushed me to think more about how deeply rooted national and organisational values can either enable or constrain international success. Overall, this assignment enhanced both my strategic thinking and cultural awareness. I developed a stronger ability to link abstract theory to real-world business issues and realised how essential it is to consider cultural compatibility alongside economic logic when advising global firms."
  },
  {
    "objectID": "projects/ml code/ml_code.html",
    "href": "projects/ml code/ml_code.html",
    "title": "Machine Learning Project Code",
    "section": "",
    "text": "# ---------------------------------------\n# 0. Import Libraries\n# ---------------------------------------\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay,f1_score, accuracy_score\nfrom tabulate import tabulate"
  },
  {
    "objectID": "projects/ml code/ml_code.html#import-libraries",
    "href": "projects/ml code/ml_code.html#import-libraries",
    "title": "Machine Learning Project Code",
    "section": "",
    "text": "# ---------------------------------------\n# 0. Import Libraries\n# ---------------------------------------\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay,f1_score, accuracy_score\nfrom tabulate import tabulate"
  },
  {
    "objectID": "projects/ml code/ml_code.html#load-dataset",
    "href": "projects/ml code/ml_code.html#load-dataset",
    "title": "Machine Learning Project Code",
    "section": "1. Load Dataset",
    "text": "1. Load Dataset\n\n# ---------------------------------------\n# 1. Load Dataset\n# ---------------------------------------\nfile = '/Users/davidbyrne/Documents/ML Research Paper/creditcard.csv'\ndata = pd.read_csv(file)"
  },
  {
    "objectID": "projects/ml code/ml_code.html#exploratory-data-analysis",
    "href": "projects/ml code/ml_code.html#exploratory-data-analysis",
    "title": "Machine Learning Project Code",
    "section": "2. Exploratory Data Analysis",
    "text": "2. Exploratory Data Analysis\n\n# ---------------------------------------\n# 2. Exploratory Data Analysis (EDA)\n# ---------------------------------------\n\n#2.1 Inspect structure and missing values\nprint(\"Dataset preview:\")\nprint(data.head())\nprint(\"\\nDataset info:\")\nprint(data.info())\nprint(\"\\nMissing values by column:\")\nprint(data.isna().sum())  # ADDED: print missing values summary\n\nDataset preview:\n   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]\n\nDataset info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\nNone\n\nMissing values by column:\nTime      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64\n\n\n\n#2.2 Class imbalance overview\n#Get class counts\ndata.Class.value_counts()\nlabels=[\"Genuine\",\"Fraud\"]\nis_it_fraud = data[\"Class\"].value_counts().tolist()\nvalues = [is_it_fraud[0], is_it_fraud[1]]\n\n#Pie chart of class proportions\n\nplt.figure(figsize=(6, 6))\nplt.pie(values, labels=labels, autopct='%1.2f%%', startangle=0, colors=['skyblue', 'lightcoral'])\nplt.title(\"Fraud vs Genuine Transactions Pie Chart\", fontsize=15)\nplt.axis('equal') \nplt.show()\n\n#Bar chart of raw class counts\nplt.figure(figsize=(6,6))\nax = sns.countplot(x='Class',data=data,color=\"skyblue\")\nfor i in ax.containers:\n    ax.bar_label(i,)\n    \nplt.title(\"Fraud vs Genuine Transactions Bar Chart\", fontsize=15)\nplt.xlabel(\"Class (0 = Genuine, 1 = Fraud)\")\nplt.ylabel(\"Count\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#2.3 Feature correlations\ncorr_matrix = data.corr()\n\n#Plot correlation heatmap\nplt.figure(figsize=(16, 12))\nsns.heatmap(corr_matrix, cmap='coolwarm', center=0, linewidths=0.5)\nplt.title(\"Correlation Matrix of All Features\", fontsize=15)\nplt.show()\n\n#Top 10 feature correlation\ntop_corr = corr_matrix['Class'].abs().sort_values(ascending=False).head(10)\nprint('Top 10 features by absolute correlation with Class:')\nprint(top_corr)\n\n\n\n\n\n\n\n\nTop 10 features by absolute correlation with Class:\nClass    1.000000\nV17      0.326481\nV14      0.302544\nV12      0.260593\nV10      0.216883\nV16      0.196539\nV3       0.192961\nV7       0.187257\nV11      0.154876\nV4       0.133447\nName: Class, dtype: float64\n\n\n\n# 2.4 Amount distribution analysis\n\n#Histogram\nplt.figure(figsize=(8, 5))\nsns.histplot(data['Amount'], bins=100, kde=True)\nplt.title(\"Distribution of Transaction Amounts\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n#Boxplot\nsns.boxplot(x='Class', y='Amount', data=data)\nplt.title(\"Transaction Amount by Class (0 = Genuine, 1 = Fraud)\")\nplt.show()"
  },
  {
    "objectID": "projects/ml code/ml_code.html#data-preprocessing",
    "href": "projects/ml code/ml_code.html#data-preprocessing",
    "title": "Machine Learning Project Code",
    "section": "3. Data Preprocessing",
    "text": "3. Data Preprocessing\n\n# ---------------------------------------\n# 3. Data Preprocessing\n# ---------------------------------------\n\n#3.1 Remove duplicates\n\n#Check if any duplicates are frauds\nfraud_duplicates = data[data.duplicated() & (data['Class'] == 1)]\nprint(\"Fraud duplicates:\", len(fraud_duplicates))\n\nFraud duplicates: 19\n\n\n\n#Separate fraud and non-fraud cases\nfraud = data[data['Class'] == 1]\nnon_fraud = data[data['Class'] == 0]\n\n#Drop duplicates only in non-fraud cases\nnon_fraud = non_fraud.drop_duplicates()\n\n#Combine both sets back into a single DataFrame\ndata = pd.concat([fraud, non_fraud], ignore_index=True)\n\n#Confirm new shape and class balance\nprint(\"Data shape after cleaning:\", data.shape)\nprint(\"Class distribution after cleaning:\\n\", data['Class'].value_counts())\n\nData shape after cleaning: (283745, 31)\nClass distribution after cleaning:\n Class\n0    283253\n1       492\nName: count, dtype: int64\n\n\n\n#3.2 Drop irrelevant columns\n\n#Drop non-numeric column used for previous visualisations\nif 'Class_Label' in data.columns:\n    data.drop(columns=['Class_Label'], inplace=True)\n\n#Drop 'Time'\nif 'Time' in data.columns:\n    data.drop(columns=['Time'], inplace=True)\n\n\n#3.3 Split features and target\n\n#Feature/target split\nX = data.drop('Class', axis=1)\ny = data['Class']\n\n\n#3.4 Train-test split with stratification\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n\nprint(\"Training shape:\", X_train.shape)\nprint(\"Test shape:\", X_test.shape)\nprint(\"Fraud in training set:\", y_train.sum())\nprint(\"Fraud in test set:\", y_test.sum())\n\nTraining shape: (198621, 29)\nTest shape: (85124, 29)\nFraud in training set: 344\nFraud in test set: 148\n\n\n\n# 3.5 Address class imbalance with SMOTE\n\n#Set fraud class to 30% of training data (vs 50% default)\nsmote = SMOTE(\n    sampling_strategy=0.1, \n    k_neighbors=2,          \n    random_state=42\n)\nX_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n\nprint(\"\\nAfter SMOTE:\")\nprint(\"Total training rows:\", X_train_sm.shape[0])\nprint(\"Fraud cases:\", y_train_sm.sum())\nprint(\"Genuine cases:\", len(y_train_sm) - y_train_sm.sum())\n\n\nAfter SMOTE:\nTotal training rows: 218104\nFraud cases: 19827\nGenuine cases: 198277"
  },
  {
    "objectID": "projects/ml code/ml_code.html#model-training-evaluation",
    "href": "projects/ml code/ml_code.html#model-training-evaluation",
    "title": "Machine Learning Project Code",
    "section": "4. Model Training & Evaluation",
    "text": "4. Model Training & Evaluation\n\n# ---------------------------------------\n# 4. Model Training & Evaluation\n# ---------------------------------------\n\n#Helper to evaluate a model\n\ndef evaluate_model(name, y_true, y_pred, y_proba=None):\n    print(f\"\\n=== {name} Evaluation ===\")\n    print(confusion_matrix(y_true, y_pred))\n    print(classification_report(y_true, y_pred, digits=4))\n    if y_proba is not None:\n        auc = roc_auc_score(y_true, y_proba)\n        print(f\"ROC AUC: {auc:.4f}\")\n\n\n#4.1 Model 1 - Logistic Regression\n\n#Training Logistic Regression Model\nlog_reg = LogisticRegression(max_iter=1000, random_state=42)\nlog_reg.fit(X_train_sm, y_train_sm)\n\n#Predict on test set\ny_pred_log = log_reg.predict(X_test)\ny_proba_log = log_reg.predict_proba(X_test)[:, 1]\n\n#Evaluate Logistic Regression Performance\nevaluate_model('Logistic Regression', y_test, y_pred_log, y_proba_log)\n\n\n=== Logistic Regression Evaluation ===\n[[84870   106]\n [   31   117]]\n              precision    recall  f1-score   support\n\n           0     0.9996    0.9988    0.9992     84976\n           1     0.5247    0.7905    0.6307       148\n\n    accuracy                         0.9984     85124\n   macro avg     0.7621    0.8946    0.8150     85124\nweighted avg     0.9988    0.9984    0.9986     85124\n\nROC AUC: 0.9611\n\n\n\n#4.2 Model 2 - XGBoost\n\n#Training XGBoost Model\nxgb = XGBClassifier(\n    scale_pos_weight=10,  \n    max_depth=2,\n    learning_rate=0.05,\n    min_child_weight=5,\n    gamma=0.3,\n    subsample=0.7,\n    eval_metric='logloss',  \n    random_state=42\n)\nxgb.fit(X_train_sm, y_train_sm)  \n\n#Predict on test set\ny_proba_xgb = xgb.predict_proba(X_test)[:, 1]\ny_pred_xgb = (y_proba_xgb &gt; 0.9).astype(int)\n\n#Evaluate XGBoost Performance\nevaluate_model('XGBoost (0.9 threshold)', y_test, y_pred_xgb, y_proba_xgb)\n\n\n=== XGBoost (0.9 threshold) Evaluation ===\n[[84911    65]\n [   37   111]]\n              precision    recall  f1-score   support\n\n           0     0.9996    0.9992    0.9994     84976\n           1     0.6307    0.7500    0.6852       148\n\n    accuracy                         0.9988     85124\n   macro avg     0.8151    0.8746    0.8423     85124\nweighted avg     0.9989    0.9988    0.9989     85124\n\nROC AUC: 0.9645\n\n\n\n#4.3 Model 3 - GaussianNB\n\n#Training GaussianNB Model\nnb = GaussianNB()\nnb.fit(X_train_sm, y_train_sm)\n\n#Predict on test set\ny_pred_nb = nb.predict(X_test)\ny_proba_nb = nb.predict_proba(X_test)[:, 1]\n\n#Evaluate GaussianNB Performance\nevaluate_model('GaussianNB', y_test, y_pred_nb, y_proba_nb)\n\n\n=== GaussianNB Evaluation ===\n[[83053  1923]\n [   33   115]]\n              precision    recall  f1-score   support\n\n           0     0.9996    0.9774    0.9884     84976\n           1     0.0564    0.7770    0.1052       148\n\n    accuracy                         0.9770     85124\n   macro avg     0.5280    0.8772    0.5468     85124\nweighted avg     0.9980    0.9770    0.9868     85124\n\nROC AUC: 0.9410\n\n\n\n#4.4 Model 4 - Random Forest with GridSearchCV\n\n#Training Random Forest Model with Hyperparameter Tuning\n\n#Set Parameters\nparam_grid = {\n    'n_estimators': [100],\n    'max_depth': [3, 5],  \n    'min_samples_leaf': [5, 10],  \n    'max_features': [0.7, 'sqrt'], \n    'class_weight': [{0:1, 1:3}]  \n}\n#Setup GridSearchCV with 3 folds\ngrid_rf = GridSearchCV(\n    estimator=RandomForestClassifier(random_state=42),\n    param_grid=param_grid,\n    scoring='recall',  \n    cv=3,              \n    n_jobs=-1,\n    verbose=0         \n)\n\n#Fit on SMOTE-balanced training set\ngrid_rf.fit(X_train_sm, y_train_sm)\n\n#Save the best tuned model\nbest_rf = grid_rf.best_estimator_\n\n#Print best parameters\nprint(\"Best RF Params:\", grid_rf.best_params_)\n\n#Predict on test set\ny_pred_rf = best_rf.predict(X_test)\ny_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n\n#Evaluate Random Forest Performance \nevaluate_model('Random Forest', y_test, y_pred_rf, y_proba_rf)\n\nBest RF Params: {'class_weight': {0: 1, 1: 3}, 'max_depth': 5, 'max_features': 0.7, 'min_samples_leaf': 5, 'n_estimators': 100}\n\n=== Random Forest Evaluation ===\n[[84864   112]\n [   37   111]]\n              precision    recall  f1-score   support\n\n           0     0.9996    0.9987    0.9991     84976\n           1     0.4978    0.7500    0.5984       148\n\n    accuracy                         0.9982     85124\n   macro avg     0.7487    0.8743    0.7988     85124\nweighted avg     0.9987    0.9982    0.9984     85124\n\nROC AUC: 0.9546"
  },
  {
    "objectID": "projects/ml code/ml_code.html#results-comparison",
    "href": "projects/ml code/ml_code.html#results-comparison",
    "title": "Machine Learning Project Code",
    "section": "5. Results Comparison",
    "text": "5. Results Comparison\n\n# ---------------------------------------\n# 5. Results Comparison\n# ---------------------------------------\n\n#Create Model Comparison Table\nresults = [\n    [\"Logistic Regression\", 0.525, 0.791, 106],\n    [\"Random Forest\", 0.498, 0.750, 112],\n    [\"XGBoost (0.9 threshold)\", 0.631, 0.750, 65],\n    [\"GaussianNB\", 0.056, 0.777, 1923]\n]\n\nprint(tabulate(results, \n              headers=[\"Model\", \"Precision\", \"Recall\", \"FP\"], \n              floatfmt=\".3f\",\n              tablefmt=\"github\"))\n\n| Model                   |   Precision |   Recall |   FP |\n|-------------------------|-------------|----------|------|\n| Logistic Regression     |       0.525 |    0.791 |  106 |\n| Random Forest           |       0.498 |    0.750 |  112 |\n| XGBoost (0.9 threshold) |       0.631 |    0.750 |   65 |\n| GaussianNB              |       0.056 |    0.777 | 1923 |\n\n\n\n#ROC Curve Comparison\n\n#Set up 2x3 ROC grid\nfig, axs = plt.subplots(2, 3, figsize=(18, 10))\n\n#Function to add baseline\ndef add_baseline(ax):\n    ax.plot([0, 1], [0, 1], linestyle='--', color='red')\n\n#Plot 1: Logistic Regression\nRocCurveDisplay.from_predictions(y_test, y_proba_log, ax=axs[0, 0], name='Logistic Regression')\naxs[0, 0].set_title(\"Logistic Regression\")\nadd_baseline(axs[0, 0])\n\n#Plot 2: XGBoost\nRocCurveDisplay.from_predictions(y_test, y_proba_xgb, ax=axs[0, 1], name='XGBoost')\naxs[0, 1].set_title(\"XGBoost\")\nadd_baseline(axs[0, 1])\n\n#Plot 3: GaussianNB\nRocCurveDisplay.from_predictions(y_test, y_proba_nb, ax=axs[0, 2], name='GaussianNB')\naxs[0, 2].set_title(\"GaussianNB\")\nadd_baseline(axs[0, 2])\n\n#Plot 4: Random Forest \nRocCurveDisplay.from_predictions(y_test, y_proba_rf, ax=axs[1, 0], name='Random Forest')\naxs[1, 0].set_title(\"Random Forest\")\nadd_baseline(axs[1, 0])\n\n#Plot 5: Combined ROC comparison \naxs[1, 1].set_title(\"Combined ROC Comparison\")\nRocCurveDisplay.from_predictions(y_test, y_proba_log, ax=axs[1, 1], name='Logistic')\nRocCurveDisplay.from_predictions(y_test, y_proba_xgb, ax=axs[1, 1], name='XGBoost')\nRocCurveDisplay.from_predictions(y_test, y_proba_nb, ax=axs[1, 1], name='GaussianNB')\nRocCurveDisplay.from_predictions(y_test, y_proba_rf, ax=axs[1, 1], name='Random Forest')\nadd_baseline(axs[1, 1])\n\n#Plot 6: Empty (for layout balance)\naxs[1, 2].axis('off')\n\n#Final touches\nplt.suptitle(\"ROC Curve Comparison Across All Models\", fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()\n\n\n\n\n\n\n\n\n\n#Precision-Recall Curve Comparison\n\n#Set up 2x3 grid \nfig, axs = plt.subplots(2, 3, figsize=(18, 10))\n\n#Plot 1: Logistic Regression\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_log, \n                                     ax=axs[0, 0], \n                                     name='Logistic Regression')\naxs[0, 0].set_title(\"Logistic Regression\")\naxs[0, 0].set_xlim([0, 1])  # Consistent axes\naxs[0, 0].set_ylim([0, 1])\n\n#Plot 2: XGBoost\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_xgb, \n                                     ax=axs[0, 1], \n                                     name='XGBoost (0.9 threshold)')\naxs[0, 1].set_title(\"XGBoost\")\naxs[0, 1].set_xlim([0, 1])\naxs[0, 1].set_ylim([0, 1])\n\n#Plot 3: GaussianNB\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_nb, \n                                     ax=axs[0, 2], \n                                     name='GaussianNB')\naxs[0, 2].set_title(\"GaussianNB\")\naxs[0, 2].set_xlim([0, 1])\naxs[0, 2].set_ylim([0, 1])\n\n#Plot 4: Random Forest\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_rf, \n                                     ax=axs[1, 0], \n                                     name='Random Forest')\naxs[1, 0].set_title(\"Random Forest\")\naxs[1, 0].set_xlim([0, 1])\naxs[1, 0].set_ylim([0, 1])\n\n#Plot 5: Combined Comparison\naxs[1, 1].set_title(\"Combined Precision-Recall Comparison\")\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_log, \n                                     ax=axs[1, 1], \n                                     name='Logistic')\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_xgb, \n                                     ax=axs[1, 1], \n                                     name='XGBoost')\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_nb, \n                                     ax=axs[1, 1], \n                                     name='GaussianNB')\nPrecisionRecallDisplay.from_predictions(y_test, y_proba_rf, \n                                     ax=axs[1, 1], \n                                     name='Random Forest')\n\n#Plot 6: Empty (for layout balance)\naxs[1, 2].axis('off')\n\n#Final touches\nplt.suptitle(\"Precision-Recall Curve Comparison Across All Models\", fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()"
  },
  {
    "objectID": "projects/ml code/ml_code.html#acknowledgements",
    "href": "projects/ml code/ml_code.html#acknowledgements",
    "title": "Machine Learning Project Code",
    "section": "6. Acknowledgements",
    "text": "6. Acknowledgements\n\n# ---------------------------------------\n# 6. Acknowledgements\n# ---------------------------------------\n\n# Kaggle Community Notebooks: for inspiring certain elements of the exploratory data analysis and visualisation:\n # - https://www.kaggle.com/code/marcinrutecki/smote-and-tomek-links-for-imbalanced-data\n # - https://www.kaggle.com/code/gargmanish/how-to-handle-imbalance-data-study-in-detail\n # - https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset\n\n# Michael Farayola (Lecturer): Inspiration taken from the model evaluation approach, particularly the use of ROC visualisation:\n # - https://github.com/mmfara/python_application_project/blob/main/FRAUD%20DETECTION%20IN%20CREDIT%20CARD.ipynb\n\n# ChatGPT (OpenAI): Provided troubleshooting assistance during various code errors.\n\n# All external resources used were critically evaluated and adapted, ensuring originality and alignment with the learning outcomes of this module."
  },
  {
    "objectID": "projects/baa1027_adv_python.html",
    "href": "projects/baa1027_adv_python.html",
    "title": "Machine Learning & Advanced Python",
    "section": "",
    "text": "This module built directly on the foundations we established in Semester 1, taking my grasp of NumPy, pandas, and matplotlib into deeper territory where I was introduced to the core theory and mathematics underpinning todayâ€™s most powerful algorithms. Over the course of the module we tackled nearly 500 lecture slidesâ€™ worth of material on topics such as linear regression, decision trees, support vector machines, and ensemble methods, then demonstrated our understanding through two tough exams, both of which I achieved 95% in.\nOn the practical side, we were tasked with coding a full machine learning solution, where I chose to implement a credit card fraud detection system on a real-world dataset, comparing four different classifiers, documenting the process and the results in the report below. Through this balance of theory and practical implementation, Iâ€™ve not only reinforced my ability to turn mathematical concepts into working code but also honed my skills in data preprocessing, model evaluation, and iterative improvement.\nâ–º See Full ML Algorithm Code\n\nReflective Report"
  },
  {
    "objectID": "projects/programming&visualisation.html",
    "href": "projects/programming&visualisation.html",
    "title": "Programming & Visualisation",
    "section": "",
    "text": "SQL\n\n\nWe started the semester out by learning about SQL. Throughout this learning I deepened my understanding of relational databases and SQL syntax, constructing ERDs, defining tables with proper primary and foreign keys, and mastering CRUD operations. Writing queries to join tables, calculate aggregates, and apply normalisation principles helped to sharpen my ability to think logically about data relationships and efficiencies. We had an exam on this, where I achieved 89%, which not only validated my proficiency with the core SQL concepts but also boosted my confidence to tackle complex data challenges in the future.\nâ–º See SQL Exam Work\n\n\n\n\n\n\nPower BI\n\n\nBuilding on from our work on SQL, I then delved into learning Power BI. For this, we had a group presentation of dashboards we created. We picked a dataset on USA car sales from 2014/15 covering vehicles registered between 1982 and 2015. We leveraged our skills learnt from SQL to drop unnecessary columns, standardise the text, and remove any rows with &gt;2 null values. We also added a new column so we could create more meaningful visualisations. We then created Power BI dashboards comprising key information that the companies can use, which we presented and provided recommendations based on the data. Our score for the presentation was 70%, which I think really reflected the work that was put in. Power BIâ€™s intuitive drag-and-drop interface and seamless integration with SQL make it an invaluable tool for transforming raw data into actionable insights. Iâ€™m confident that its ability to build dynamic dashboards and automate reporting will play a central role throughout my career in data analytics and finance.\nâ–º See our Power BI Dashboards\n\n\n\n\n\n\nPython\n\n\nFinally, for the last 5 weeks of the semester, we explored the basics of Python. I learned to use NumPy for efficient array operations, pandas for data cleaning and transformation, and matplotlib for creating informative visualisations. Mastering these libraries gave me practical experience with core Python data structures and plotting techniques. We had an exam on this, in which I achieved 75% in. Having this solid foundation made delving into more advanced Python topics in semester two much smoother, as I could focus on new concepts rather than basic syntax and data handling.\nâ–º See my Semester 2 Work"
  },
  {
    "objectID": "about_experience/kkr.html",
    "href": "about_experience/kkr.html",
    "title": "David Byrne",
    "section": "",
    "text": "KKR & Co Inc.Â is a leading global investment firm, managing private equity, credit, and real estate assets across multiple sectors. During my 14-month internship on the Asset, Liabilities, and Portfolio Services (ALPS) team, I supported the lifecycle management of multi-billion-dollar portfolios, tracking assets from purchase through payoff. reconciling daily cash flows, and ensuring accurate asset positions for trading purposes. I also collaborated with cross-functional teams to streamline reporting processes, had oversight of the offshore team, and developed a comprehensive training plan for ten new interns.\nThis role gave me extensive insight into the finance industry, sharpening my analytical skills and operational discipline. I learnt to navigate complex financial systems, maintain data integrity under tight deadlines, and communicate effectively with stakeholders. Designing and delivering intern training significantly improved my leadership skills and reinforced the value of clear documentation and mentorship.\nThe internship solidified my passion with financial markets. Watching credit portfolios evolve from acquisition through to payoff, and understanding how daily cash reconciliations feed into pricing and risk decisions, revealed that finance is as much about rigorous analysis as it is about real-world impact. This has inspired me to pursue the CFA qualification post-graduation, deepening my expertise in equity valuation, fixed-income analysis, and portfolio management. My long-term aspiration is to transition into a front-office role, partnering directly with clients on asset allocation strategies, contributing to deal execution, and shaping investment solutions that balance risk and return.\n\nOutside the office, playing 7-a-side football with colleagues each Monday in Irish Town was a real highlight. It helped to build camaraderie and reminded me that high performance demands both professional focus and personal balance. I still continue to play each Monday with the team, which helps to give me a release from all the college work! Unfortunately, we got demoted to division two during my internship, however, we have since gotten promoted back to division one with a much stronger squad. Iâ€™m hoping we continue this good run of form now!"
  },
  {
    "objectID": "about_experience/kkr.html#my-kkr-experience",
    "href": "about_experience/kkr.html#my-kkr-experience",
    "title": "David Byrne",
    "section": "",
    "text": "KKR & Co Inc.Â is a leading global investment firm, managing private equity, credit, and real estate assets across multiple sectors. During my 14-month internship on the Asset, Liabilities, and Portfolio Services (ALPS) team, I supported the lifecycle management of multi-billion-dollar portfolios, tracking assets from purchase through payoff. reconciling daily cash flows, and ensuring accurate asset positions for trading purposes. I also collaborated with cross-functional teams to streamline reporting processes, had oversight of the offshore team, and developed a comprehensive training plan for ten new interns.\nThis role gave me extensive insight into the finance industry, sharpening my analytical skills and operational discipline. I learnt to navigate complex financial systems, maintain data integrity under tight deadlines, and communicate effectively with stakeholders. Designing and delivering intern training significantly improved my leadership skills and reinforced the value of clear documentation and mentorship.\nThe internship solidified my passion with financial markets. Watching credit portfolios evolve from acquisition through to payoff, and understanding how daily cash reconciliations feed into pricing and risk decisions, revealed that finance is as much about rigorous analysis as it is about real-world impact. This has inspired me to pursue the CFA qualification post-graduation, deepening my expertise in equity valuation, fixed-income analysis, and portfolio management. My long-term aspiration is to transition into a front-office role, partnering directly with clients on asset allocation strategies, contributing to deal execution, and shaping investment solutions that balance risk and return.\n\nOutside the office, playing 7-a-side football with colleagues each Monday in Irish Town was a real highlight. It helped to build camaraderie and reminded me that high performance demands both professional focus and personal balance. I still continue to play each Monday with the team, which helps to give me a release from all the college work! Unfortunately, we got demoted to division two during my internship, however, we have since gotten promoted back to division one with a much stronger squad. Iâ€™m hoping we continue this good run of form now!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Check out some of the projects I have worked on throughout my academic journey!\n\n\nReflecting on the ePortfolio process as a whole, itâ€™s been a genuinely valuable and rewarding experience. Damienâ€™s guidance throughout the module made a huge difference. His interactive slides, step-by-step walkthroughs, and clear breakdown of each section made what initially seemed like a daunting task feel manageable. The way he paced the content and encouraged us to engage with it actively helped me stay on track and build confidence as I went.\nUsing Quarto and all the associated tools was completely new to me, and Iâ€™ll admit there was a learning curve at the start. Figuring out how to format everything, organise the layout, and troubleshoot little issues took some time, but once I got into the flow, it became a lot more intuitive. By the end, I felt proud of how much Iâ€™d learned, from Markdown and HTML basics to how to present my academic and professional journey in a clear, structured way.\nLooking ahead, I fully intend to continue updating my ePortfolio throughout my career. Itâ€™s a powerful tool, not only for reflecting on how far Iâ€™ve come, but also for showcasing my skills, projects, and experiences to future employers. In such a competitive job market, I know having a well-crafted, living portfolio will really help me stand out."
  },
  {
    "objectID": "projects.html#reflection-on-the-eportfolio",
    "href": "projects.html#reflection-on-the-eportfolio",
    "title": "Projects",
    "section": "",
    "text": "Reflecting on the ePortfolio process as a whole, itâ€™s been a genuinely valuable and rewarding experience. Damienâ€™s guidance throughout the module made a huge difference. His interactive slides, step-by-step walkthroughs, and clear breakdown of each section made what initially seemed like a daunting task feel manageable. The way he paced the content and encouraged us to engage with it actively helped me stay on track and build confidence as I went.\nUsing Quarto and all the associated tools was completely new to me, and Iâ€™ll admit there was a learning curve at the start. Figuring out how to format everything, organise the layout, and troubleshoot little issues took some time, but once I got into the flow, it became a lot more intuitive. By the end, I felt proud of how much Iâ€™d learned, from Markdown and HTML basics to how to present my academic and professional journey in a clear, structured way.\nLooking ahead, I fully intend to continue updating my ePortfolio throughout my career. Itâ€™s a powerful tool, not only for reflecting on how far Iâ€™ve come, but also for showcasing my skills, projects, and experiences to future employers. In such a competitive job market, I know having a well-crafted, living portfolio will really help me stand out."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "David Byrne",
    "section": "",
    "text": "Final Year Business Studies Student in DCU (Analytics Specialism), expected to graduate with first-class honours. I have a strong academic record, achieving 613 points in the Leaving Certificate and a 1.1 grade across the first and second years of the Business Studies curriculum. Gained invaluable experience in the Finance industry through a year-long internship with KKR & Co Inc.Â Complemented by certifications in SQL, Python, and financial modeling, I am poised to contribute effectively to an analytical role upon graduation in May 2025.\nReview my CV"
  },
  {
    "objectID": "about.html#core-skills",
    "href": "about.html#core-skills",
    "title": "David Byrne",
    "section": "Core Skills",
    "text": "Core Skills\n\n\n\n\n\n\nPython\nExperienced in Python for ML workflows: data cleaning, exploratory analysis, model development, tuning, evaluation\nâ†’ View Python Projects\n\n\n\n\n\n\n\nSQL\nProficient in SQL for database querying, data manipulation, and management, ensuring data integrity and accessibility\nâ†’ View SQL Work\n\n\n\n\n\n\n\nPower BI\nSkilled in Power BI, built an interactive US car sales dashboard with DAX metrics, filters, and visualisations\nâ†’ View Dashboards"
  },
  {
    "objectID": "about.html#my-experience",
    "href": "about.html#my-experience",
    "title": "David Byrne",
    "section": "My Experience",
    "text": "My Experience\n\n\n\n\nDublin City University\nAnalytics specialism, final-year Business Studies\nâ†’ Read more about my DCU Experience\n\n\n\n\n\nKKR & Co.Â Internship\nYear-long internship in a leading Private Equity firm\nâ†’ Read more about my KKR Internship"
  },
  {
    "objectID": "about.html#some-videos-im-interested-in",
    "href": "about.html#some-videos-im-interested-in",
    "title": "David Byrne",
    "section": "Some Videos Iâ€™m Interested In",
    "text": "Some Videos Iâ€™m Interested In"
  },
  {
    "objectID": "about.html#hobbies-interests",
    "href": "about.html#hobbies-interests",
    "title": "David Byrne",
    "section": "Hobbies & Interests",
    "text": "Hobbies & Interests\n\n\n\n\n\n\nFootball\nEnjoy to play 7-a-side each Monday and 5-aside each Wednesday\n\n\n\n\n\n\n\nGym\nRegular strength and cardio workouts\n\n\n\n\n\n\n\nHiking\nExploring local trails and national parks"
  },
  {
    "objectID": "about_experience/dcu.html#representing-dcu-at-sg-fecc-usa",
    "href": "about_experience/dcu.html#representing-dcu-at-sg-fecc-usa",
    "title": "David Byrne",
    "section": "Representing DCU at SG-FECC (USA)",
    "text": "Representing DCU at SG-FECC (USA)\n\nIn January 2025, I was lucky enough to be one of four students selected from the DCU Business School to represent the university at the Schlesinger Global Family Enterprise Case Competition in Burlington, Vermont, USA. This experience was definitely the biggest highlight of my time at university. We spent a week dissecting our pre-arrival case, then faced three days of closed cases, each limited to just four hours of offline analysis. In that tight window, we identified the problems, developed three recommendations as well as alternative recommendations, mapped out implementation timelines, and created presentation slides. We then presented for twenty minutes to a talented panel of judges, from private equity managers to retired Amazon executives, where they then quizzed us for a ten-minute Q&A session. There was intense time pressure as we had barely any time to rehearse our pitches before presenting, but our preparation and trust in one another paid off as we topped our division every single day, earning a perfect score of 16/16 points. Competing against universities from the US, Canada, Mexico, and Germany, I saw my presentation skills sharpen, my ability to remain composed under extreme time constraints deepen, and my confidence in group collaboration soar.\nOutside of competition hours, exploring Burlingtonâ€™s snowy streets reminded me that growth often happens outside our comfort zones, and that the friendships and professional lessons gained are among my most treasured takeaways from DCU."
  },
  {
    "objectID": "about_experience/dcu.html#future-goals",
    "href": "about_experience/dcu.html#future-goals",
    "title": "David Byrne",
    "section": "Future Goals",
    "text": "Future Goals\nLooking ahead, I am excited to build on the strong foundation I have developed at DCU and during my 14-month internship with KKR. My immediate goal post-graduation is to begin working towards the Chartered Financial Analyst (CFA) qualification, deepening my expertise in investment analysis and portfolio management. The analytical skills and real-world financial knowledge I have gained, both through my degree and my internship experience, have prepared me well for the challenges of the CFA programme.\nAlongside this, I aspire to move into a front-office finance role, where I can work directly with clients on asset allocation strategies, investment decisions, and broader financial solutions. I am passionate about this career path and I believe my experience so far has given me the right balance of technical, professional, and interpersonal skills to succeed. As I continue to grow, I am excited to apply what I have learned, and what I will continue to learn, to make a real impact in the world of finance."
  }
]